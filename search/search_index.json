{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome \u00b6 Greetings and welcome to my note book. Here you can find useful information about tech. Contact me","title":"Welcome"},{"location":"#welcome","text":"Greetings and welcome to my note book. Here you can find useful information about tech.","title":"Welcome"},{"location":"DevOps/","text":"DevOps notes \u00b6 Every time I start new project, I think about where it can be deployed and how can I deploy it. In this articles I gather things to help you in setting up your dev environment and deploy on bare metal servers or with a cloud solution.","title":"DevOps notes"},{"location":"DevOps/#devops-notes","text":"Every time I start new project, I think about where it can be deployed and how can I deploy it. In this articles I gather things to help you in setting up your dev environment and deploy on bare metal servers or with a cloud solution.","title":"DevOps notes"},{"location":"DevOps/Docker%20envs%20separation/","text":"Separating docker envs \u00b6 Should we separate docker environments in several docker-compose files in your projects? Definitely! In some cases you can't figure out what developers wanted to do or why project doesn't work. Setting up separation between dev and prod environments can become a mishmash. In this article I'll show you the easiest way for setting up docker-compose for your project and how to avoid millon problems. How can we separate environments for local development and production? The answer is simple. We need to decompose our project and create separate files for environments or even a services. It's totally ok if you have more than 2 docker-compose files. For example: deploy \u251c\u2500\u2500 docker-compose.autotests.yml \u251c\u2500\u2500 docker-compose.db.yml \u251c\u2500\u2500 docker-compose.dev.yml \u251c\u2500\u2500 docker-compose.yml \u251c\u2500\u2500 dockerfiles \u2502 \u251c\u2500\u2500 api.Dockerfile \u2502 \u2514\u2500\u2500 front.Dockerfile \u2514\u2500\u2500 scripts \u251c\u2500\u2500 start-autotests.sh \u251c\u2500\u2500 start-backend.sh \u2514\u2500\u2500 start-migrations.sh How does it work? \u00b6 Docker can work with multiple docker-compose files simultaneously. And we can use it for environment separation. It looks like this: docker-compose \\ -f \"deploy/docker-compose.yml\" \\ -f \"deploy/docker-compose.db.yml\" \\ -f \"deploy/docker-compose.dev.yml\" \\ up In each docker-compose file we define a part of the configuration, which doesn't inersect with others. For example: docker-compose.yml defines our application and some required services. In other compose files we define services or override existing configurations defined in previous files. I guess, it simpler to show it by example. Let's imagine, that you have a project that can be started with different parameters, and they are different for local and production. Let's create simple project with the following stucture: proj \u251c\u2500\u2500 deploy \u2502 \u251c\u2500\u2500 docker-compose.yml \u2502 \u2514\u2500\u2500 dockerfiles \u2502 \u2514\u2500\u2500 script.Dockerfile \u2514\u2500\u2500 script.py Let's write a simple python script. # script.py from sys import argv # \u044d\u0442\u043e \u0430\u0440\u0433\u0443\u043c\u0435\u0442\u044b \u043f\u0435\u0440\u0435\u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u0441\u043a\u0440\u0438\u043f\u0442 def main(): print(\"; \".join(argv[1:])) # \u0432\u044b\u0432\u043e\u0434\u0438\u0442\u043d\u0430 \u044d\u043a\u0440\u0430\u043d \u0432\u0441\u0435 \u0430\u0440\u0433\u0443\u043c\u0435\u043d\u0442\u044b \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u044b if __name__ == \"__main__\": main() After that we need to wrap it into docker container by creating Dockerfile in deploy/dockerfiles/script.Dockerfile from python:3.8 # asd WORKDIR /app COPY script.py /app/script.py CMD python /app/script.py As you can see, Dockerifle is very simple. Now let's create the main docker-compose.yml . --- # deploy/docker-compose.yml version: '3.7' services: script: build: # build applicationo. dockerfile: ./deploy/dockerfiles/script.Dockerfile context: . # \u0417\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u043c \u0435\u0433\u043e \u0441 \u043a\u043e\u043c\u0430\u043d\u0434\u043e\u0439 \u0434\u043b\u044f \u043f\u0440\u043e\u0434\u043e\u0432\u043e\u0433\u043e \u0437\u0430\u043f\u0443\u0441\u043a\u0430. command: python script.py this is prod Now we can start this project with that command: d-test docker-compose \\ -f \"./deploy/docker-compose.yml\" \\ --project-directory \".\" \\ run --rm script It will print: Creating d-test_script_run ... done this; is; prod As we can see it has printed a message we've passed in our docker-compose.yml . Now we are going to configure environment for local development without changing the main docker-compose.yml . Let's create the docker-compose.dev.yml --- # deploy/docker-compose.dev.yml version: '3.7' services: script: command: python script.py this is dev Now add this file in our startup script and run it. d-test docker-compose \\ -f \"deploy/docker-compose.yml\" \\ -f \"deploy/docker-compose.dev.yml\" \\ --project-directory \".\" \\ run --rm script It'll print the following: Creating d-test\\_script\\_run ... done this; is; dev As you can see, deploy configuration was overwritten with our new file. Any mentioned file in this command can add new services or partially override previously mentioned files. Complete project structure: proj \u251c\u2500\u2500 deploy \u2502 \u251c\u2500\u2500 docker-compose.dev.yml \u2502 \u251c\u2500\u2500 docker-compose.yml \u2502 \u2514\u2500\u2500 dockerfiles \u2502 \u2514\u2500\u2500 script.Dockerfile \u2514\u2500\u2500 script.py Where can I use that? \u00b6 In every project bigger than this one. Because the real life not so friendly and local environment of the project can be different to the production not only by configuration, but the whole services.","title":"Separating docker envs"},{"location":"DevOps/Docker%20envs%20separation/#separating-docker-envs","text":"Should we separate docker environments in several docker-compose files in your projects? Definitely! In some cases you can't figure out what developers wanted to do or why project doesn't work. Setting up separation between dev and prod environments can become a mishmash. In this article I'll show you the easiest way for setting up docker-compose for your project and how to avoid millon problems. How can we separate environments for local development and production? The answer is simple. We need to decompose our project and create separate files for environments or even a services. It's totally ok if you have more than 2 docker-compose files. For example: deploy \u251c\u2500\u2500 docker-compose.autotests.yml \u251c\u2500\u2500 docker-compose.db.yml \u251c\u2500\u2500 docker-compose.dev.yml \u251c\u2500\u2500 docker-compose.yml \u251c\u2500\u2500 dockerfiles \u2502 \u251c\u2500\u2500 api.Dockerfile \u2502 \u2514\u2500\u2500 front.Dockerfile \u2514\u2500\u2500 scripts \u251c\u2500\u2500 start-autotests.sh \u251c\u2500\u2500 start-backend.sh \u2514\u2500\u2500 start-migrations.sh","title":"Separating docker envs"},{"location":"DevOps/Docker%20envs%20separation/#how-does-it-work","text":"Docker can work with multiple docker-compose files simultaneously. And we can use it for environment separation. It looks like this: docker-compose \\ -f \"deploy/docker-compose.yml\" \\ -f \"deploy/docker-compose.db.yml\" \\ -f \"deploy/docker-compose.dev.yml\" \\ up In each docker-compose file we define a part of the configuration, which doesn't inersect with others. For example: docker-compose.yml defines our application and some required services. In other compose files we define services or override existing configurations defined in previous files. I guess, it simpler to show it by example. Let's imagine, that you have a project that can be started with different parameters, and they are different for local and production. Let's create simple project with the following stucture: proj \u251c\u2500\u2500 deploy \u2502 \u251c\u2500\u2500 docker-compose.yml \u2502 \u2514\u2500\u2500 dockerfiles \u2502 \u2514\u2500\u2500 script.Dockerfile \u2514\u2500\u2500 script.py Let's write a simple python script. # script.py from sys import argv # \u044d\u0442\u043e \u0430\u0440\u0433\u0443\u043c\u0435\u0442\u044b \u043f\u0435\u0440\u0435\u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u0441\u043a\u0440\u0438\u043f\u0442 def main(): print(\"; \".join(argv[1:])) # \u0432\u044b\u0432\u043e\u0434\u0438\u0442\u043d\u0430 \u044d\u043a\u0440\u0430\u043d \u0432\u0441\u0435 \u0430\u0440\u0433\u0443\u043c\u0435\u043d\u0442\u044b \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u044b if __name__ == \"__main__\": main() After that we need to wrap it into docker container by creating Dockerfile in deploy/dockerfiles/script.Dockerfile from python:3.8 # asd WORKDIR /app COPY script.py /app/script.py CMD python /app/script.py As you can see, Dockerifle is very simple. Now let's create the main docker-compose.yml . --- # deploy/docker-compose.yml version: '3.7' services: script: build: # build applicationo. dockerfile: ./deploy/dockerfiles/script.Dockerfile context: . # \u0417\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u043c \u0435\u0433\u043e \u0441 \u043a\u043e\u043c\u0430\u043d\u0434\u043e\u0439 \u0434\u043b\u044f \u043f\u0440\u043e\u0434\u043e\u0432\u043e\u0433\u043e \u0437\u0430\u043f\u0443\u0441\u043a\u0430. command: python script.py this is prod Now we can start this project with that command: d-test docker-compose \\ -f \"./deploy/docker-compose.yml\" \\ --project-directory \".\" \\ run --rm script It will print: Creating d-test_script_run ... done this; is; prod As we can see it has printed a message we've passed in our docker-compose.yml . Now we are going to configure environment for local development without changing the main docker-compose.yml . Let's create the docker-compose.dev.yml --- # deploy/docker-compose.dev.yml version: '3.7' services: script: command: python script.py this is dev Now add this file in our startup script and run it. d-test docker-compose \\ -f \"deploy/docker-compose.yml\" \\ -f \"deploy/docker-compose.dev.yml\" \\ --project-directory \".\" \\ run --rm script It'll print the following: Creating d-test\\_script\\_run ... done this; is; dev As you can see, deploy configuration was overwritten with our new file. Any mentioned file in this command can add new services or partially override previously mentioned files. Complete project structure: proj \u251c\u2500\u2500 deploy \u2502 \u251c\u2500\u2500 docker-compose.dev.yml \u2502 \u251c\u2500\u2500 docker-compose.yml \u2502 \u2514\u2500\u2500 dockerfiles \u2502 \u2514\u2500\u2500 script.Dockerfile \u2514\u2500\u2500 script.py","title":"How does it work?"},{"location":"DevOps/Docker%20envs%20separation/#where-can-i-use-that","text":"In every project bigger than this one. Because the real life not so friendly and local environment of the project can be different to the production not only by configuration, but the whole services.","title":"Where can I use that?"},{"location":"DevOps/Makefiles%20for%20dummies/","text":"Makefiles for dummies \u00b6 If we want to describe Makefiles in a nutshell, than we might say it's thing for describing command to ease interaction with the project. Initially Makefiles were created to conveniently compile projects written in any language. How does it work \u00b6 It works pretty simple. Here's an example of a Makefile : # Generate bash file. test.gen: @echo 'echo \"Hi!\"' > \"test.gen\" # Run generated file test.gen .PHONY: run run: test.gen sh \"test.gen\" Before colons we define our targets. E.G in this example we have test.gen and run targets. These targets can be triggered with command like make ${target} . If we enter make run in terminal in a dir with Makefile we'll get the following: sh \"test.gen\" Hi! As we can see in output, we successfully ran the run target which read the test.gen file, but we didn't run make test.gen target. What happened? Let's dive into it. Targets dependencies \u00b6 On the line where we define our run target, we can see the test.gen target places right after the colon. This is a dependency of the run target, it fires right before executing the run target. Each target can have multiple dependencies, they are spearated with space. E.G.: .PHONY: target1 target1: echo \"1\" .PHONY: target2 target2: target1 echo \"2\" .PHONY: target3 target3: target1 target2 echo \"memes\" Let's call the target3 target and see the output. make target3 echo \"1\" 1 echo \"2\" 2 echo \"memes\" memes As you can see, Makefile has built the target dependency tree and didn't call the target1 second time. Hiding commands output \u00b6 In previous example you can notice that make command printed out all shell commands for every target. You can hide the commands from the output by adding \"@\" at the start of a command. Like this: .PHONY: target1 target1: @echo \"1\" .PHONY: target2 target2: target1 @echo \"2\" .PHONY: target3 target3: target1 target2 @echo \"memes\" Now you can call targets and it won't print the actual commands. Like this: make target3 1 2 memes Generated files validation \u00b6 Make files are often used for compiling C programs and sometimes you need to compile a part of a project and skip building this part if executable is already present. It's a basic functionality of Makefiles. Let's change the first Makefile and call the run target twice. # Generate bash file. test.gen: echo 'echo \"Hi!\"' > \"test.gen\" # Run generated file test.gen .PHONY: run run: test.gen sh \"test.gen\" Now we can see which commands Makefile executes. Let's run it. make run echo 'echo \"Hi!\"' > \"test.gen\" sh \"test.gen\" Hi! make run sh \"test.gen\" Hi! As you can see, second time it has skipped the run of a test.gen target. It's because name of a target is a filename and it will never execute the target if file with name equals to target name exists. That is, in that particular case the test.gen target have to generate the test.gen file during the execution, and if it's already present it doesn't update it. That's why it didn't run it for the second time. If you don't want to have that feature you can disable it by adding .PHONY: ${target} somewhere. Like this: .PHONY: test.gen # Generate bash file test.gen: echo 'echo \"Hi!\"' > \"test.gen\" # Run generated file test.gen .PHONY: run run: test.gen sh \"test.gen\" Now it executes test.gen every time it's called. make run echo 'echo \"Hi!\"' > \"test.gen\" sh \"test.gen\" Hi! make run echo 'echo \"Hi!\"' > \"test.gen\" sh \"test.gen\" Hi!","title":"Makefiles for dummies"},{"location":"DevOps/Makefiles%20for%20dummies/#makefiles-for-dummies","text":"If we want to describe Makefiles in a nutshell, than we might say it's thing for describing command to ease interaction with the project. Initially Makefiles were created to conveniently compile projects written in any language.","title":"Makefiles for dummies"},{"location":"DevOps/Makefiles%20for%20dummies/#how-does-it-work","text":"It works pretty simple. Here's an example of a Makefile : # Generate bash file. test.gen: @echo 'echo \"Hi!\"' > \"test.gen\" # Run generated file test.gen .PHONY: run run: test.gen sh \"test.gen\" Before colons we define our targets. E.G in this example we have test.gen and run targets. These targets can be triggered with command like make ${target} . If we enter make run in terminal in a dir with Makefile we'll get the following: sh \"test.gen\" Hi! As we can see in output, we successfully ran the run target which read the test.gen file, but we didn't run make test.gen target. What happened? Let's dive into it.","title":"How does it work"},{"location":"DevOps/Makefiles%20for%20dummies/#targets-dependencies","text":"On the line where we define our run target, we can see the test.gen target places right after the colon. This is a dependency of the run target, it fires right before executing the run target. Each target can have multiple dependencies, they are spearated with space. E.G.: .PHONY: target1 target1: echo \"1\" .PHONY: target2 target2: target1 echo \"2\" .PHONY: target3 target3: target1 target2 echo \"memes\" Let's call the target3 target and see the output. make target3 echo \"1\" 1 echo \"2\" 2 echo \"memes\" memes As you can see, Makefile has built the target dependency tree and didn't call the target1 second time.","title":"Targets dependencies"},{"location":"DevOps/Makefiles%20for%20dummies/#hiding-commands-output","text":"In previous example you can notice that make command printed out all shell commands for every target. You can hide the commands from the output by adding \"@\" at the start of a command. Like this: .PHONY: target1 target1: @echo \"1\" .PHONY: target2 target2: target1 @echo \"2\" .PHONY: target3 target3: target1 target2 @echo \"memes\" Now you can call targets and it won't print the actual commands. Like this: make target3 1 2 memes","title":"Hiding commands output"},{"location":"DevOps/Makefiles%20for%20dummies/#generated-files-validation","text":"Make files are often used for compiling C programs and sometimes you need to compile a part of a project and skip building this part if executable is already present. It's a basic functionality of Makefiles. Let's change the first Makefile and call the run target twice. # Generate bash file. test.gen: echo 'echo \"Hi!\"' > \"test.gen\" # Run generated file test.gen .PHONY: run run: test.gen sh \"test.gen\" Now we can see which commands Makefile executes. Let's run it. make run echo 'echo \"Hi!\"' > \"test.gen\" sh \"test.gen\" Hi! make run sh \"test.gen\" Hi! As you can see, second time it has skipped the run of a test.gen target. It's because name of a target is a filename and it will never execute the target if file with name equals to target name exists. That is, in that particular case the test.gen target have to generate the test.gen file during the execution, and if it's already present it doesn't update it. That's why it didn't run it for the second time. If you don't want to have that feature you can disable it by adding .PHONY: ${target} somewhere. Like this: .PHONY: test.gen # Generate bash file test.gen: echo 'echo \"Hi!\"' > \"test.gen\" # Run generated file test.gen .PHONY: run run: test.gen sh \"test.gen\" Now it executes test.gen every time it's called. make run echo 'echo \"Hi!\"' > \"test.gen\" sh \"test.gen\" Hi! make run echo 'echo \"Hi!\"' > \"test.gen\" sh \"test.gen\" Hi!","title":"Generated files validation"},{"location":"Python/","text":"Python notes \u00b6 All notes gathered in this section are about the Python language. The Python itself is a very pleasant language and helps to build project prototypes really fast.","title":"Python notes"},{"location":"Python/#python-notes","text":"All notes gathered in this section are about the Python language. The Python itself is a very pleasant language and helps to build project prototypes really fast.","title":"Python notes"},{"location":"Python/How%20to%20start%20a%20python%20project/","text":"How to start a project \u00b6 You have several options. For example you can store a bunch of .py files in repo on github and be fully satisfied, or you can add the setup.py script and publish it on pypi, but the best option as I can see is to start and develop your project with poetry. Why? Poetry has many features. I'm here to tell you about them, and how to use it and what to do. Let's create a project with poetry. poetry new new_proj Created package new_proj in new_proj cd new_proj This command generates project with the following structure: new_proj \u251c\u2500\u2500 new_proj \u2502 \u2514\u2500\u2500 __init__.py \u251c\u2500\u2500 pyproject.toml \u251c\u2500\u2500 README.rst \u2514\u2500\u2500 tests \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 test_new_proj.py It's our brand new project with several stubs. There is nothing unusual. All the code you want to write will be placed in a directory with the same name as the project. README.rst is the default README. pyproject.toml contains meta-data about project, such as dependencies, description, extra installation options and more. You can read about pyproject.toml here . How to deal with poetry \u00b6 All the information you need you can find in official documentation poetry. I'll tell you about basic stuff here. Dependency management \u00b6 To add a dependency to your project you can simply run this: poetry add ${dependency} This command finds the last convinient version of the dependency and writes it to the pyproject.toml and poetry.lock . To add dependency only for development, such as linters or formatters, you can add the --dev flag. poetry add ${dependency} --dev To remove dependency you simply need to replace add with remove . Working example: poetry add loguru Using version ^0.5.3 for loguru Updating dependencies Resolving dependencies... (0.1s) Writing lock file Package operations: 1 install, 0 updates, 0 removals \u2022 Installing loguru (0.5.3) poetry remove loguru Updating dependencies Resolving dependencies... (0.1s) Writing lock file Package operations: 0 installs, 0 updates, 1 removal \u2022 Removing loguru (0.5.3) Running commands \u00b6 With virtual environment you need to write something like this, to enter the shell: source venv/bin/activate But with poetry it's much easier. It creates and manages virtual envs on it's own. To run a single command you can call run . E.G.: poetry install black --dev Using version ^20.8b1 for black \u2022 Installing appdirs (1.4.4) \u2022 Installing click (7.1.2) \u2022 Installing mypy-extensions (0.4.3) \u2022 Installing pathspec (0.8.1) \u2022 Installing regex (2020.11.13) \u2022 Installing toml (0.10.2) \u2022 Installing typed-ast (1.4.2) \u2022 Installing typing-extensions (3.7.4.3) \u2022 Installing black (20.8b1) poetry run black . reformatted new_proj/new_proj/__init__.py reformatted new_proj/tests/test_new_proj.py All done! \u2728 \ud83c\udf70 \u2728 2 files reformatted, 1 file left unchanged. For executing multiple commands within the shell you can enter interactive shell session with poetry shell . It's similar to virtualenv's source venv/bin/activate . poetry shell Spawning shell within /home/s3rius/.cache/pypoetry/virtualenvs/new-proj-eutP4v0O-py3.9 black . reformatted new_proj/new_proj/__init__.py reformatted new_proj/tests/test_new_proj.py All done! \u2728 \ud83c\udf70 \u2728 2 files reformatted, 1 file left unchanged. Versioning \u00b6 With poetry you don't need to change package versions manually. The Poetry has something for you. poetry version patch Bumping version from 0.1.0 to 0.1.1 poetry version preminor Bumping version from 0.1.1 to 0.2.0-alpha.0 poetry version minor Bumping version from 0.2.0-alpha.0 to 0.2.0 poetry version premajor Bumping version from 0.2.0 to 1.0.0-alpha.0 poetry version major Bumping version from 1.0.0-alpha.0 to 1.0.0 pyproject.toml \u00b6 As mentioned before this file contains package's meta-information. Example of pyproject.toml [tool.poetry] name = \"new_proj\" version = \"0.1.0\" description = \"Test library for example\" readme = \"README.rst\" homepage = \"https://test_url.com/\" repository = \"https://github.meme/\" authors = [\"Pavel Kirilin <win10@list.ru>\"] [tool.poetry.dependencies] python = \"^3.8\" [tool.poetry.dev-dependencies] pytest = \"^6.1\" [build-system] requires = [\"poetry-core>=1.0.0\"] build-backend = \"poetry.core.masonry.api\" To install all dependencies simply run: poetry install This command creates virtual environment and installs dependencies from the pyproject.toml file. If you want install dependencies only for runtime you can add --no-dev . Packaging and publishing on pypi \u00b6 It's really simple. Let's add a function in the project. # new_proj/main.py def ab_problem(a: int, b: int) -> int: return a + b # new_proj/__init.py from new_proj.main import ab_problem __all__ = [ 'ab_problem' ] Now you can build the project. poetry build Building new_proj (0.1.0) - Building sdist - Built new_proj-0.1.0.tar.gz - Building wheel - Built new_proj-0.1.0-py3-none-any.whl You can find ready for publication package in dist/ folder. Let's check if everything works. pip install \"./dist/new_proj-0.1.0-py3-none-any.whl\" Processing ./dist/new_proj-0.1.0-py3-none-any.whl Installing collected packages: new-proj Successfully installed new-proj-0.1.0 python Python 3.9.1 (default, Feb 1 2021, 04:02:33) [GCC 10.2.0] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. from new_proj import ab_problem ab_problem(1,33) 34 It works! Now we can use it. If you want to publish the package you can run: poetry publish -u \"user\" -p \"password\" More information you can find here . Configuring project \u00b6 Project without configuration is a bad thing. Let's configure development environment. poetry add \\ flake8 \\ black \\ isort \\ mypy \\ pre-commit \\ yesqa \\ autoflake \\ wemake-python-styleguide --dev Now we need to add configuration files for linters and formatters. This is my preffered configurations, you can change it as you wish. .mypy.ini for types validation. [mypy] strict = True ignore_missing_imports=True allow_subclassing_any=True allow_untyped_calls=True pretty=True show_error_codes=True implicit_reexport=True allow_untyped_decorators=True .isort.cfg for import sorting. [isort] multi_line_output = 3 include_trailing_comma = true use_parentheses = true .flake8 - Linter configuration. Biggest part of the document is ignore statements for errors that's not really an errors. [flake8] max-complexity = 6 inline-quotes = double max-line-length = 88 extend-ignore = E203 docstring_style=sphinx ignore = ; Found `f` string WPS305, ; Missing docstring in public module D100, ; Missing docstring in magic method D105, ; Missing docstring in __init__ D107, ; Found class without a base class WPS306, ; Missing docstring in public nested class D106, ; First line should be in imperative mood D401, ; Found `__init__.py` module with logic WPS412, ; Found implicit string concatenation WPS326, ; Found string constant over-use WPS226, ; Found upper-case constant in a class WPS115, ; Found nested function WPS430, ; Found using `@staticmethod` WPS602, ; Found method without arguments WPS605, ; Found overused expression WPS204, ; Found too many module members WPS202, ; Found too high module cognitive complexity WPS232, ; line break before binary operator W503, ; Found module with too many imports WPS201, ; Found vague import that may cause confusion: X WPS347, ; Inline strong start-string without end-string. RST210, ; subprocess call with shell=True seems safe, but may be changed in the future. S602, ; Starting a process with a partial executable path. S607, ; Consider possible security implications associated with subprocess module. S404, ; Found nested class WPS431, ; Found wrong module name WPS100, ; Found too many methods WPS214, ; Found too long ``try`` body WPS229, ; Found function with too much cognitive complexity WPS231, ; all init files __init__.py: ; ignore not used imports F401, ; ignore import with wildcard F403, ; Found wrong metadata variable WPS410, per-file-ignores = ; all tests test_*.py,tests.py,tests_*.py,*/tests/*: ; Use of assert detected S101, exclude = ./.git, ./venv, ./cached_venv, ./var, .pre-commit-config.yaml - Git hooks configuration. To perform all checks right before git commit . # See https://pre-commit.com for more information # See https://pre-commit.com/hooks.html for more hooks repos: - repo: https://github.com/pre-commit/pre-commit-hooks rev: v2.4.0 hooks: - id: check-ast - id: trailing-whitespace - id: check-toml - id: end-of-file-fixer - repo: https://github.com/asottile/add-trailing-comma rev: v2.1.0 hooks: - id: add-trailing-comma - repo: local hooks: - id: black name: Format with Black entry: black language: system types: [python] - id: autoflake name: autoflake entry: autoflake language: system types: [ python ] args: [ --in-place, --remove-all-unused-imports, --remove-duplicate-keys ] - id: isort name: isort entry: isort language: system types: [ python ] - id: flake8 name: Check with Flake8 entry: flake8 language: system pass_filenames: false types: [ python ] args: [--count, .] - id: mypy name: Validate types with MyPy entry: mypy language: system types: [ python ] - id: yesqa name: Remove usless noqa entry: yesqa language: system types: [ python ] - id: pytest name: pytest entry: pytest language: system pass_filenames: false types: [ python ] Don't forget to add .gitignore . You can find it here . It' REALLY IMPORTANT for correct work of pre-commit. Now we can install hooks. git init Initialized empty Git repository in .git/ poetry shell pre-commit install pre-commit installed at .git/hooks/pre-commit git commit ... # It will have a lot of errors. Let's fix it. At first we need to fix tests. In tests/test_new_proj.py add this: from new_proj import ab_problem def test_ab() -> None: \"\"\"AB problecm success case.\"\"\" assert ab_problem(1, 2) == 3 Add a description in __init__ files. tests/__init__.py : \"\"\"Tests for new_proj.\"\"\" new_proj/__init__.py : \"\"\"Project for solving ab problem.\"\"\" from new_proj.main import ab_problem __all__ = [ \"ab_problem\", ] Fix the main file of a project. new_proj/main.py : def ab_problem(first: int, second: int) -> int: \"\"\" Solve AB problem. The function sums two integers. :param first: a argument. :param second: b argument. :returns: sum. \"\"\" return first + second Now you can commit without errors. git commit Check python ast................Passed Trim Trailing Whitespace........Passed Check Toml......................Passed Fix End of Files................Passed Add trailing commas.............Passed Format with Black...............Passed autoflake.......................Passed isort...........................Passed Check with Flake8...............Passed Validate types with MyPy........Passed Remove usless noqa..............Passed pytest..........................Passed Now you know how to create a masterpiece. Creating CLI tool \u00b6 What if I want to create a CLI-tool? It easier than you think. Let's modify our main file. import argparse def parse_args() -> argparse.Namespace: \"\"\" Parse CLI arguments. :returns: parsed namespace. \"\"\" parser = argparse.ArgumentParser() parser.add_argument(\"a\", type=int) parser.add_argument(\"b\", type=int) return parser.parse_args() def ab_problem(first: int, second: int) -> int: \"\"\" Solve AB problem. The function sums two integers. :param first: a argument. :param second: b argument. :returns: sum. \"\"\" return first + second def main() -> None: \"\"\"Main function.\"\"\" args = parse_args() print(ab_problem(args.a, args.b)) # noqa: WPS421 Now we need to change the pyproject.toml . Add the following section somewhere in pyproject.toml . [tool.poetry.scripts] ab_solver = \"new_proj.main:main\" Now you can use the ab_solver in your terminal. poetry install poetry shell ab_solver 1 2 3 Do you want to install it globally in the system? Here you go. poetry build Building new_proj (0.1.0) - Building sdist - Built new_proj-0.1.0.tar.gz - Building wheel - Built new_proj-0.1.0-py3-none-any.whl pip install \"./dist/new_proj-0.1.0-py3-none-any.whl\" Processing ./dist/new_proj-0.1.0-py3-none-any.whl Installing collected packages: new-proj Successfully installed new-proj-0.1.0 ab_solver 1 2 3 If you publish your project in pypi or anywhere else. Users who install your program will get it as the cli-tool.","title":"How to start a project"},{"location":"Python/How%20to%20start%20a%20python%20project/#how-to-start-a-project","text":"You have several options. For example you can store a bunch of .py files in repo on github and be fully satisfied, or you can add the setup.py script and publish it on pypi, but the best option as I can see is to start and develop your project with poetry. Why? Poetry has many features. I'm here to tell you about them, and how to use it and what to do. Let's create a project with poetry. poetry new new_proj Created package new_proj in new_proj cd new_proj This command generates project with the following structure: new_proj \u251c\u2500\u2500 new_proj \u2502 \u2514\u2500\u2500 __init__.py \u251c\u2500\u2500 pyproject.toml \u251c\u2500\u2500 README.rst \u2514\u2500\u2500 tests \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 test_new_proj.py It's our brand new project with several stubs. There is nothing unusual. All the code you want to write will be placed in a directory with the same name as the project. README.rst is the default README. pyproject.toml contains meta-data about project, such as dependencies, description, extra installation options and more. You can read about pyproject.toml here .","title":"How to start a project"},{"location":"Python/How%20to%20start%20a%20python%20project/#how-to-deal-with-poetry","text":"All the information you need you can find in official documentation poetry. I'll tell you about basic stuff here.","title":"How to deal with poetry"},{"location":"Python/How%20to%20start%20a%20python%20project/#dependency-management","text":"To add a dependency to your project you can simply run this: poetry add ${dependency} This command finds the last convinient version of the dependency and writes it to the pyproject.toml and poetry.lock . To add dependency only for development, such as linters or formatters, you can add the --dev flag. poetry add ${dependency} --dev To remove dependency you simply need to replace add with remove . Working example: poetry add loguru Using version ^0.5.3 for loguru Updating dependencies Resolving dependencies... (0.1s) Writing lock file Package operations: 1 install, 0 updates, 0 removals \u2022 Installing loguru (0.5.3) poetry remove loguru Updating dependencies Resolving dependencies... (0.1s) Writing lock file Package operations: 0 installs, 0 updates, 1 removal \u2022 Removing loguru (0.5.3)","title":"Dependency management"},{"location":"Python/How%20to%20start%20a%20python%20project/#running-commands","text":"With virtual environment you need to write something like this, to enter the shell: source venv/bin/activate But with poetry it's much easier. It creates and manages virtual envs on it's own. To run a single command you can call run . E.G.: poetry install black --dev Using version ^20.8b1 for black \u2022 Installing appdirs (1.4.4) \u2022 Installing click (7.1.2) \u2022 Installing mypy-extensions (0.4.3) \u2022 Installing pathspec (0.8.1) \u2022 Installing regex (2020.11.13) \u2022 Installing toml (0.10.2) \u2022 Installing typed-ast (1.4.2) \u2022 Installing typing-extensions (3.7.4.3) \u2022 Installing black (20.8b1) poetry run black . reformatted new_proj/new_proj/__init__.py reformatted new_proj/tests/test_new_proj.py All done! \u2728 \ud83c\udf70 \u2728 2 files reformatted, 1 file left unchanged. For executing multiple commands within the shell you can enter interactive shell session with poetry shell . It's similar to virtualenv's source venv/bin/activate . poetry shell Spawning shell within /home/s3rius/.cache/pypoetry/virtualenvs/new-proj-eutP4v0O-py3.9 black . reformatted new_proj/new_proj/__init__.py reformatted new_proj/tests/test_new_proj.py All done! \u2728 \ud83c\udf70 \u2728 2 files reformatted, 1 file left unchanged.","title":"Running commands"},{"location":"Python/How%20to%20start%20a%20python%20project/#versioning","text":"With poetry you don't need to change package versions manually. The Poetry has something for you. poetry version patch Bumping version from 0.1.0 to 0.1.1 poetry version preminor Bumping version from 0.1.1 to 0.2.0-alpha.0 poetry version minor Bumping version from 0.2.0-alpha.0 to 0.2.0 poetry version premajor Bumping version from 0.2.0 to 1.0.0-alpha.0 poetry version major Bumping version from 1.0.0-alpha.0 to 1.0.0","title":"Versioning"},{"location":"Python/How%20to%20start%20a%20python%20project/#pyprojecttoml","text":"As mentioned before this file contains package's meta-information. Example of pyproject.toml [tool.poetry] name = \"new_proj\" version = \"0.1.0\" description = \"Test library for example\" readme = \"README.rst\" homepage = \"https://test_url.com/\" repository = \"https://github.meme/\" authors = [\"Pavel Kirilin <win10@list.ru>\"] [tool.poetry.dependencies] python = \"^3.8\" [tool.poetry.dev-dependencies] pytest = \"^6.1\" [build-system] requires = [\"poetry-core>=1.0.0\"] build-backend = \"poetry.core.masonry.api\" To install all dependencies simply run: poetry install This command creates virtual environment and installs dependencies from the pyproject.toml file. If you want install dependencies only for runtime you can add --no-dev .","title":"pyproject.toml"},{"location":"Python/How%20to%20start%20a%20python%20project/#packaging-and-publishing-on-pypi","text":"It's really simple. Let's add a function in the project. # new_proj/main.py def ab_problem(a: int, b: int) -> int: return a + b # new_proj/__init.py from new_proj.main import ab_problem __all__ = [ 'ab_problem' ] Now you can build the project. poetry build Building new_proj (0.1.0) - Building sdist - Built new_proj-0.1.0.tar.gz - Building wheel - Built new_proj-0.1.0-py3-none-any.whl You can find ready for publication package in dist/ folder. Let's check if everything works. pip install \"./dist/new_proj-0.1.0-py3-none-any.whl\" Processing ./dist/new_proj-0.1.0-py3-none-any.whl Installing collected packages: new-proj Successfully installed new-proj-0.1.0 python Python 3.9.1 (default, Feb 1 2021, 04:02:33) [GCC 10.2.0] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. from new_proj import ab_problem ab_problem(1,33) 34 It works! Now we can use it. If you want to publish the package you can run: poetry publish -u \"user\" -p \"password\" More information you can find here .","title":"Packaging and publishing on pypi"},{"location":"Python/How%20to%20start%20a%20python%20project/#configuring-project","text":"Project without configuration is a bad thing. Let's configure development environment. poetry add \\ flake8 \\ black \\ isort \\ mypy \\ pre-commit \\ yesqa \\ autoflake \\ wemake-python-styleguide --dev Now we need to add configuration files for linters and formatters. This is my preffered configurations, you can change it as you wish. .mypy.ini for types validation. [mypy] strict = True ignore_missing_imports=True allow_subclassing_any=True allow_untyped_calls=True pretty=True show_error_codes=True implicit_reexport=True allow_untyped_decorators=True .isort.cfg for import sorting. [isort] multi_line_output = 3 include_trailing_comma = true use_parentheses = true .flake8 - Linter configuration. Biggest part of the document is ignore statements for errors that's not really an errors. [flake8] max-complexity = 6 inline-quotes = double max-line-length = 88 extend-ignore = E203 docstring_style=sphinx ignore = ; Found `f` string WPS305, ; Missing docstring in public module D100, ; Missing docstring in magic method D105, ; Missing docstring in __init__ D107, ; Found class without a base class WPS306, ; Missing docstring in public nested class D106, ; First line should be in imperative mood D401, ; Found `__init__.py` module with logic WPS412, ; Found implicit string concatenation WPS326, ; Found string constant over-use WPS226, ; Found upper-case constant in a class WPS115, ; Found nested function WPS430, ; Found using `@staticmethod` WPS602, ; Found method without arguments WPS605, ; Found overused expression WPS204, ; Found too many module members WPS202, ; Found too high module cognitive complexity WPS232, ; line break before binary operator W503, ; Found module with too many imports WPS201, ; Found vague import that may cause confusion: X WPS347, ; Inline strong start-string without end-string. RST210, ; subprocess call with shell=True seems safe, but may be changed in the future. S602, ; Starting a process with a partial executable path. S607, ; Consider possible security implications associated with subprocess module. S404, ; Found nested class WPS431, ; Found wrong module name WPS100, ; Found too many methods WPS214, ; Found too long ``try`` body WPS229, ; Found function with too much cognitive complexity WPS231, ; all init files __init__.py: ; ignore not used imports F401, ; ignore import with wildcard F403, ; Found wrong metadata variable WPS410, per-file-ignores = ; all tests test_*.py,tests.py,tests_*.py,*/tests/*: ; Use of assert detected S101, exclude = ./.git, ./venv, ./cached_venv, ./var, .pre-commit-config.yaml - Git hooks configuration. To perform all checks right before git commit . # See https://pre-commit.com for more information # See https://pre-commit.com/hooks.html for more hooks repos: - repo: https://github.com/pre-commit/pre-commit-hooks rev: v2.4.0 hooks: - id: check-ast - id: trailing-whitespace - id: check-toml - id: end-of-file-fixer - repo: https://github.com/asottile/add-trailing-comma rev: v2.1.0 hooks: - id: add-trailing-comma - repo: local hooks: - id: black name: Format with Black entry: black language: system types: [python] - id: autoflake name: autoflake entry: autoflake language: system types: [ python ] args: [ --in-place, --remove-all-unused-imports, --remove-duplicate-keys ] - id: isort name: isort entry: isort language: system types: [ python ] - id: flake8 name: Check with Flake8 entry: flake8 language: system pass_filenames: false types: [ python ] args: [--count, .] - id: mypy name: Validate types with MyPy entry: mypy language: system types: [ python ] - id: yesqa name: Remove usless noqa entry: yesqa language: system types: [ python ] - id: pytest name: pytest entry: pytest language: system pass_filenames: false types: [ python ] Don't forget to add .gitignore . You can find it here . It' REALLY IMPORTANT for correct work of pre-commit. Now we can install hooks. git init Initialized empty Git repository in .git/ poetry shell pre-commit install pre-commit installed at .git/hooks/pre-commit git commit ... # It will have a lot of errors. Let's fix it. At first we need to fix tests. In tests/test_new_proj.py add this: from new_proj import ab_problem def test_ab() -> None: \"\"\"AB problecm success case.\"\"\" assert ab_problem(1, 2) == 3 Add a description in __init__ files. tests/__init__.py : \"\"\"Tests for new_proj.\"\"\" new_proj/__init__.py : \"\"\"Project for solving ab problem.\"\"\" from new_proj.main import ab_problem __all__ = [ \"ab_problem\", ] Fix the main file of a project. new_proj/main.py : def ab_problem(first: int, second: int) -> int: \"\"\" Solve AB problem. The function sums two integers. :param first: a argument. :param second: b argument. :returns: sum. \"\"\" return first + second Now you can commit without errors. git commit Check python ast................Passed Trim Trailing Whitespace........Passed Check Toml......................Passed Fix End of Files................Passed Add trailing commas.............Passed Format with Black...............Passed autoflake.......................Passed isort...........................Passed Check with Flake8...............Passed Validate types with MyPy........Passed Remove usless noqa..............Passed pytest..........................Passed Now you know how to create a masterpiece.","title":"Configuring project"},{"location":"Python/How%20to%20start%20a%20python%20project/#creating-cli-tool","text":"What if I want to create a CLI-tool? It easier than you think. Let's modify our main file. import argparse def parse_args() -> argparse.Namespace: \"\"\" Parse CLI arguments. :returns: parsed namespace. \"\"\" parser = argparse.ArgumentParser() parser.add_argument(\"a\", type=int) parser.add_argument(\"b\", type=int) return parser.parse_args() def ab_problem(first: int, second: int) -> int: \"\"\" Solve AB problem. The function sums two integers. :param first: a argument. :param second: b argument. :returns: sum. \"\"\" return first + second def main() -> None: \"\"\"Main function.\"\"\" args = parse_args() print(ab_problem(args.a, args.b)) # noqa: WPS421 Now we need to change the pyproject.toml . Add the following section somewhere in pyproject.toml . [tool.poetry.scripts] ab_solver = \"new_proj.main:main\" Now you can use the ab_solver in your terminal. poetry install poetry shell ab_solver 1 2 3 Do you want to install it globally in the system? Here you go. poetry build Building new_proj (0.1.0) - Building sdist - Built new_proj-0.1.0.tar.gz - Building wheel - Built new_proj-0.1.0-py3-none-any.whl pip install \"./dist/new_proj-0.1.0-py3-none-any.whl\" Processing ./dist/new_proj-0.1.0-py3-none-any.whl Installing collected packages: new-proj Successfully installed new-proj-0.1.0 ab_solver 1 2 3 If you publish your project in pypi or anywhere else. Users who install your program will get it as the cli-tool.","title":"Creating CLI tool"}]}